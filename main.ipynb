{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-22T10:55:08.981382Z",
     "start_time": "2025-05-22T10:55:02.948404Z"
    }
   },
   "source": [
    "!pip install PyWavelets\n",
    "!pip install pyts\n",
    "!pip install aeon"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyWavelets in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from PyWavelets) (2.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyts in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from pyts) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.8.1 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from pyts) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.2.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from pyts) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from pyts) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.55.2 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from pyts) (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from numba>=0.55.2->pyts) (0.43.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from scikit-learn>=1.2.0->pyts) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aeon in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from aeon) (1.2.18)\n",
      "Requirement already satisfied: numba<0.61.0,>=0.55 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from aeon) (0.60.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.21.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from aeon) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from aeon) (24.2)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from aeon) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn<1.6.0,>=1.0.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from aeon) (1.5.2)\n",
      "Requirement already satisfied: scipy<1.15.0,>=1.9.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from aeon) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from aeon) (4.13.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from deprecated>=1.2.13->aeon) (1.17.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from numba<0.61.0,>=0.55->aeon) (0.43.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->aeon) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->aeon) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->aeon) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from scikit-learn<1.6.0,>=1.0.0->aeon) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from scikit-learn<1.6.0,>=1.0.0->aeon) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bruno\\puc\\iniciacao\\projeto\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.0.0->aeon) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T10:55:10.545222Z",
     "start_time": "2025-05-22T10:55:08.982385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from aeon.transformations.collection.convolution_based import Rocket, MiniRocket\n",
    "from aeon.datasets.tsc_datasets import multivariate\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from utils import config\n",
    "from utils.config import DATASETS_FOLDER, logger\n",
    "from utils.utils import transform_series, dimensions_fusion, load_dataset, PAA"
   ],
   "id": "6e74a7ab5f5c84fa",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Configurações",
   "id": "790b0230694dfe5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T10:55:10.549744Z",
     "start_time": "2025-05-22T10:55:10.546229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RESULTS_FILENAME = f'results_final.csv'\n",
    "\n",
    "reps = ['RP', 'MTF', 'GASF', 'GADF', 'FIRTS', 'CWT']\n",
    "operations = [\"sum\", \"subtraction\", \"dot_product\", \"element_wise\"]\n"
   ],
   "id": "e56718d2b9450db8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T10:55:10.557369Z",
     "start_time": "2025-05-22T10:55:10.550858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    df_results = pd.read_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\")\n",
    "except FileNotFoundError:\n",
    "    df_results = pd.DataFrame(columns=[\n",
    "        \"dataset\",\n",
    "        \"representation\",\n",
    "        \"operation\",\n",
    "        \"accuracy\",\n",
    "        \"convolution_algorithm\",\n",
    "        \"classification_algorithm\",\n",
    "    ])"
   ],
   "id": "135bce14a87d3be7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Gerando resultados com apenas o classficador Ridge sem nenhuma transformação ou convolução",
   "id": "2a8c38b12b6a3413"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T10:55:43.046256Z",
     "start_time": "2025-05-22T10:55:10.557369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dataset_name in multivariate:\n",
    "    if df_results[\n",
    "        (df_results[\"dataset\"] == dataset_name)\n",
    "        & (df_results[\"representation\"].isnull())\n",
    "        & (df_results[\"operation\"].isnull())\n",
    "    ].shape[0] == 1:\n",
    "        logger.info(f\"Dataset {dataset_name} já processado.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        dataset = load_dataset(dataset_name, DATASETS_FOLDER)\n",
    "        X_train = dataset[\"X_train\"]\n",
    "        y_train = dataset[\"y_train\"]\n",
    "        X_test = dataset[\"X_test\"]\n",
    "        y_test = dataset[\"y_test\"]\n",
    "\n",
    "        try:\n",
    "            try:\n",
    "                result = np.sum(X_train[0], axis=0)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Erro na soma das metrizes:{e}\")\n",
    "            X_train_transformed = np.array([np.sum(serie, axis=0) for serie in X_train])\n",
    "            X_test_transformed = np.array([np.sum(serie, axis=0) for serie in X_test])\n",
    "\n",
    "            classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "            classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "            accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "            new_result_line = {\n",
    "                \"dataset\": dataset_name,\n",
    "                \"representation\": None,\n",
    "                \"operation\": None,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"convolution_algorithm\": None,\n",
    "                \"classification_algorithm\": \"Ridge\",\n",
    "            }\n",
    "            df_results.loc[len(df_results)] = new_result_line\n",
    "            df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "            \n",
    "            logger.info(\"Processamento finalizado com sucesso.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Problema com o dataset {dataset_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Problema ao carregar dataset {dataset_name}: {e}\")\n"
   ],
   "id": "49e16e93b83d2422",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 11\u001B[39m\n\u001B[32m      8\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m     dataset = \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDATASETS_FOLDER\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m     X_train = dataset[\u001B[33m\"\u001B[39m\u001B[33mX_train\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     13\u001B[39m     y_train = dataset[\u001B[33m\"\u001B[39m\u001B[33my_train\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\utils\\utils.py:19\u001B[39m, in \u001B[36mload_dataset\u001B[39m\u001B[34m(dataset_name, dataset_folder)\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     17\u001B[39m     logger.info(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mCarregando \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m     X_train, y_train = \u001B[43mload_from_ts_file\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdataset_folder\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdataset_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdataset_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m_TRAIN.ts\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m     X_test, y_test = load_from_ts_file(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_TEST.ts\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     22\u001B[39m     logger.info(\u001B[33m\"\u001B[39m\u001B[33mCarregamento finalizado com sucesso\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\aeon\\datasets\\_data_loaders.py:282\u001B[39m, in \u001B[36mload_from_ts_file\u001B[39m\u001B[34m(full_file_path_and_name, replace_missing_vals_with, return_meta_data, return_type)\u001B[39m\n\u001B[32m    280\u001B[39m     meta_data = _load_header_info(file)\n\u001B[32m    281\u001B[39m     \u001B[38;5;66;03m# load into list of numpy\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m282\u001B[39m     data, y, meta_data = \u001B[43m_load_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeta_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[38;5;66;03m# if equal load to 3D numpy\u001B[39;00m\n\u001B[32m    285\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m meta_data[\u001B[33m\"\u001B[39m\u001B[33mequallength\u001B[39m\u001B[33m\"\u001B[39m]:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\aeon\\datasets\\_data_loaders.py:176\u001B[39m, in \u001B[36m_load_data\u001B[39m\u001B[34m(file, meta_data, replace_missing_vals_with)\u001B[39m\n\u001B[32m    174\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m meta_data[\u001B[33m\"\u001B[39m\u001B[33mclasslabel\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m meta_data[\u001B[33m\"\u001B[39m\u001B[33mtargetlabel\u001B[39m\u001B[33m\"\u001B[39m]:\n\u001B[32m    175\u001B[39m     target = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m176\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    177\u001B[39m \u001B[43m    \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstrip\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m \u001B[43m    \u001B[49m\u001B[43mline\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mline\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mnan\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreplace_missing_vals_with\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m<frozen codecs>:319\u001B[39m, in \u001B[36mdecode\u001B[39m\u001B[34m(self, input, final)\u001B[39m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Aplicar Up sampling\n",
    "- Down sampling\n",
    "- Aplicar o PCA\n",
    "- Boxplot com apenas uma categoria\n",
    "- Pegar a média dos visinhos quando for nan\n",
    "\n",
    "- Mostrar gráficos com"
   ],
   "id": "a50e02a4a84c3f2a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Gerando resultados com o classficador Ridge, transformações e convoluções",
   "id": "def0ecfbb9eff538"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-22T10:55:43.047701Z",
     "start_time": "2025-05-22T10:55:43.046256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# datasets = multivariate\n",
    "# for dataset in config.SKIP_DATASETS:\n",
    "#     datasets.remove(dataset)\n",
    "\n",
    "for dataset_name in [\"Heartbeat\"]:\n",
    "    try:\n",
    "        if df_results[\n",
    "            (df_results[\"dataset\"] == dataset_name)\n",
    "            & ~(df_results[\"representation\"].isnull())\n",
    "        ].shape[0] == len(reps) * len(operations) * 3: # Teste sem convolução, com Rocket e com MiniRocket\n",
    "            logger.info(f\"Dataset {dataset_name} já processado.\")\n",
    "            continue\n",
    "\n",
    "        dataset = load_dataset(dataset_name, config.DATASETS_FOLDER)\n",
    "        X_train = dataset[\"X_train\"][:4]\n",
    "        y_train = dataset[\"y_train\"][:4]\n",
    "        X_test = dataset[\"X_test\"][:4]\n",
    "        y_test = dataset[\"y_test\"][:4]\n",
    "\n",
    "        for representation in reps:\n",
    "            if df_results[\n",
    "                (df_results[\"dataset\"] == dataset_name)\n",
    "                & (df_results[\"representation\"] == representation)\n",
    "            ].shape[0] == len(operations) * 3: # Teste sem convolução, com Rocket e com MiniRocket \n",
    "                logger.info(f\"Dataset {dataset_name} com representação {representation} já processado.\")\n",
    "                continue\n",
    "            \n",
    "            logger.info(f\"Iniciando o processo de transformação das dimensões na representação {representation}\")\n",
    "\n",
    "            transformed_train_series = []\n",
    "            for exemple in X_train:\n",
    "                transformed_train_series.append(\n",
    "                    [PAA(transform_series(series, representation), 20) for series in exemple]\n",
    "                )\n",
    "            transformed_test_series = []\n",
    "            for exemple in X_test:\n",
    "                transformed_test_series.append(\n",
    "                    [PAA(transform_series(series, representation), 20) for series in exemple]\n",
    "                )\n",
    "\n",
    "            logger.info(\"Finalizado processo de transformação das dimensões com sucesso\")\n",
    "\n",
    "            for operation in operations:\n",
    "                if df_results[\n",
    "                    (df_results[\"dataset\"] == dataset_name)\n",
    "                    & (df_results[\"representation\"] == representation)\n",
    "                    & (df_results[\"operation\"] == operation)\n",
    "                ].shape[0] == 3: # Teste sem convolução, com Rocket e com MiniRocket \n",
    "                    logger.info(f\"Dataset {dataset_name}, representação {representation} e operação {operation} todos as variações já processadas.\")\n",
    "                    continue\n",
    "                \n",
    "                logger.info(f\"Iniciando processo de fusão das dimensões na operação {operation}\")\n",
    "                X_train_transformed = dimensions_fusion(transformed_train_series, operation)\n",
    "                X_test_transformed = dimensions_fusion(transformed_test_series, operation)\n",
    "                \n",
    "                # TODO: Verify if contains NANs \n",
    "                \n",
    "                \n",
    "                logger.info(\"Finalizado processo de fusão\")\n",
    "\n",
    "                try:\n",
    "                    if df_results[\n",
    "                        (df_results[\"dataset\"] == dataset_name)\n",
    "                        & (df_results[\"representation\"] == representation)\n",
    "                        & (df_results[\"operation\"] == operation)\n",
    "                        & (df_results[\"convolution_algorithm\"].isnull())\n",
    "                    ].shape[0] == 0:\n",
    "                        logger.info(\"Iniciando processo de treinamento apenas com o classificador Ridge\")\n",
    "                        classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "                        classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "                        accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "                        new_result_line = {\n",
    "                            \"dataset\": dataset_name,\n",
    "                            \"representation\": representation,\n",
    "                            \"operation\": operation,\n",
    "                            \"accuracy\": accuracy,\n",
    "                            \"convolution_algorithm\": None,\n",
    "                            \"classification_algorithm\": \"Ridge\",\n",
    "                        }\n",
    "                        df_results.loc[len(df_results)] = new_result_line\n",
    "                        df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "                    else:\n",
    "                        logger.info(f\"Dataset {dataset_name} com representação {representation}, operação {operation} e sem convolução já processado.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Problema com o dataset {dataset_name} com o classificador Ridge: {e}\")\n",
    "\n",
    "                try:\n",
    "                    if df_results[\n",
    "                        (df_results[\"dataset\"] == dataset_name)\n",
    "                        & (df_results[\"representation\"] == representation)\n",
    "                        & (df_results[\"operation\"] == operation)\n",
    "                        & (df_results[\"convolution_algorithm\"] == \"Rocket\")\n",
    "                    ].shape[0] == 0:\n",
    "                        logger.info(\"Iniciando processo de treinamento com o classificador Ridge e convolução Rocket\")\n",
    "\n",
    "                        algorithm = Rocket(n_kernels=10000, n_jobs=-1, random_state=6)\n",
    "                        algorithm.fit(X_train_transformed)\n",
    "\n",
    "                        X_train_transformed = algorithm.transform(X_train_transformed)\n",
    "                        X_test_transformed = algorithm.transform(X_test_transformed)\n",
    "\n",
    "                        classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "                        classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "                        accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "                        new_result_line = {\n",
    "                            \"dataset\": dataset_name,\n",
    "                            \"representation\": representation,\n",
    "                            \"operation\": operation,\n",
    "                            \"accuracy\": accuracy,\n",
    "                            \"convolution_algorithm\": \"Rocket\",\n",
    "                            \"classification_algorithm\": \"Ridge\",\n",
    "                        }\n",
    "                        df_results.loc[len(df_results)] = new_result_line\n",
    "                        df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "                    else:\n",
    "                        logger.info(f\"Dataset {dataset_name} com representação {representation}, operação {operation} e com convolução Rocket já processado.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Problema com o dataset {dataset_name} usando Rocket: {e}\")\n",
    "\n",
    "                try:\n",
    "                    if df_results[\n",
    "                        (df_results[\"dataset\"] == dataset_name)\n",
    "                        & (df_results[\"representation\"] == representation)\n",
    "                        & (df_results[\"operation\"] == operation)\n",
    "                        & (df_results[\"convolution_algorithm\"] == \"MiniRocket\")\n",
    "                    ].shape[0] == 0:\n",
    "                        logger.info(\"Iniciando processo de treinamento com o classificador Ridge e convolução MiniRocket\")\n",
    "\n",
    "                        algorithm = MiniRocket(n_kernels=10000, n_jobs=-1, random_state=6)\n",
    "                        algorithm.fit(X_train_transformed)\n",
    "\n",
    "                        X_train_transformed = algorithm.transform(X_train_transformed)\n",
    "                        X_test_transformed = algorithm.transform(X_test_transformed)\n",
    "\n",
    "                        classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "                        classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "                        accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "                        new_result_line = {\n",
    "                            \"dataset\": dataset_name,\n",
    "                            \"representation\": representation,\n",
    "                            \"operation\": operation,\n",
    "                            \"accuracy\": accuracy,\n",
    "                            \"convolution_algorithm\": \"MiniRocket\",\n",
    "                            \"classification_algorithm\": \"Ridge\",\n",
    "                        }\n",
    "                        df_results.loc[len(df_results)] = new_result_line\n",
    "                        df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "                    else:\n",
    "                        logger.info(f\"Dataset {dataset_name} com representação {representation}, operação {operation} e com convolução MiniRocket já processado.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Problema com o dataset {dataset_name} usando MiniRocket: {e}\")\n",
    "\n",
    "        logger.info(f\"Finalizado o processamento do dataset {dataset_name}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Problema ao carregar dataset {dataset_name}: {e}\")\n",
    "    \n",
    "logger.info(\"Finalizado o processamento de todos os datasets.\")\n"
   ],
   "id": "29954c0c17ff2448",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c62ac1f2a36b4767",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
