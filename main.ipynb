{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-09T20:26:09.050361Z",
     "start_time": "2025-08-09T20:26:06.808709Z"
    }
   },
   "source": "!pip install PyWavelets pyts aeon python-dotenv --quiet",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T21:13:28.541032Z",
     "start_time": "2025-08-09T21:13:28.536862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from aeon.transformations.collection.convolution_based import Rocket, MiniRocket\n",
    "from aeon.datasets.tsc_datasets import multivariate\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from utils import config\n",
    "from utils.config import logger\n",
    "from utils.utils import transform_series, dimensions_fusion, load_dataset, PAA, znorm"
   ],
   "id": "6e74a7ab5f5c84fa",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Configurações",
   "id": "790b0230694dfe5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T21:13:30.031920Z",
     "start_time": "2025-08-09T21:13:30.028740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "RESULTS_FILENAME = f'results_final.csv'\n",
    "\n",
    "reps = ['RP', 'MTF', 'GASF', 'GADF', 'FIRTS', 'CWT']\n",
    "operations = [\"sum\", \"subtraction\", \"dot_product\", \"element_wise\"]"
   ],
   "id": "e56718d2b9450db8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-09T21:13:31.428695Z",
     "start_time": "2025-08-09T21:13:31.424183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    df_results = pd.read_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\")\n",
    "except FileNotFoundError:\n",
    "    df_results = pd.DataFrame(columns=[\n",
    "        \"dataset\",\n",
    "        \"representation\",\n",
    "        \"operation\",\n",
    "        \"accuracy\",\n",
    "        \"convolution_algorithm\",\n",
    "        \"classification_algorithm\",\n",
    "    ])"
   ],
   "id": "135bce14a87d3be7",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Gerando resultados com apenas o classficador Ridge sem nenhuma transformação ou convolução",
   "id": "2a8c38b12b6a3413"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-09T21:13:35.675543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processes_datasets = multivariate\n",
    "\n",
    "for dataset_name in processes_datasets:\n",
    "    if df_results[\n",
    "        (df_results[\"dataset\"] == dataset_name)\n",
    "        & (df_results[\"representation\"].isnull())\n",
    "        & (df_results[\"operation\"].isnull())\n",
    "    ].shape[0] == 1:\n",
    "        logger.info(f\"Dataset {dataset_name} já processado.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        dataset = load_dataset(dataset_name, config.DATASETS_FOLDER)\n",
    "        X_train = dataset[\"X_train\"]\n",
    "        y_train = dataset[\"y_train\"]\n",
    "        X_test = dataset[\"X_test\"]\n",
    "        y_test = dataset[\"y_test\"]\n",
    "\n",
    "        try:\n",
    "            X_train_transformed = np.array([np.sum([znorm(series) for series in exemple], axis=0) for exemple in X_train])\n",
    "            X_test_transformed = np.array([np.sum([znorm(series) for series in exemple], axis=0) for exemple in X_test])\n",
    "            \n",
    "            classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "            classifier.fit(X_train_transformed, y_train)\n",
    "            \n",
    "            accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "            new_result_line = {\n",
    "                \"dataset\": dataset_name,\n",
    "                \"representation\": None,\n",
    "                \"operation\": None,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"convolution_algorithm\": None,\n",
    "                \"classification_algorithm\": \"Ridge\",\n",
    "            }\n",
    "            df_results.loc[len(df_results)] = new_result_line\n",
    "            df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "            \n",
    "            # Treinamento com MiniRocket\n",
    "            algorithm = MiniRocket(n_kernels=10000, n_jobs=-1, random_state=6)\n",
    "            algorithm.fit(X_train_transformed)\n",
    "            \n",
    "            X_train_convoluted = algorithm.transform(X_train_transformed)\n",
    "            X_test_convoluted = algorithm.transform(X_test_transformed)\n",
    "            \n",
    "            classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "            classifier.fit(X_train_convoluted, y_train)\n",
    "            \n",
    "            accuracy = classifier.score(X_test_convoluted, y_test)\n",
    "\n",
    "            new_result_line = {\n",
    "                \"dataset\": dataset_name,\n",
    "                \"representation\": None,\n",
    "                \"operation\": None,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"convolution_algorithm\": \"MiniRocket\",\n",
    "                \"classification_algorithm\": \"Ridge\",\n",
    "            }\n",
    "            df_results.loc[len(df_results)] = new_result_line\n",
    "            df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "            \n",
    "            # Treinamento com Rocket\n",
    "            algorithm = Rocket(n_kernels=10000, n_jobs=-1, random_state=6)\n",
    "            algorithm.fit(X_train_transformed)\n",
    "            \n",
    "            X_train_convoluted = algorithm.transform(X_train_transformed)\n",
    "            X_test_convoluted = algorithm.transform(X_test_transformed)\n",
    "            \n",
    "            classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "            classifier.fit(X_train_convoluted, y_train)\n",
    "            \n",
    "            accuracy = classifier.score(X_test_convoluted, y_test)\n",
    "\n",
    "            new_result_line = {\n",
    "                \"dataset\": dataset_name,\n",
    "                \"representation\": None,\n",
    "                \"operation\": None,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"convolution_algorithm\": \"Rocket\",\n",
    "                \"classification_algorithm\": \"Ridge\",\n",
    "            }\n",
    "            df_results.loc[len(df_results)] = new_result_line\n",
    "            df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "            \n",
    "            logger.info(\"Processamento finalizado com sucesso.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Problema com o dataset {dataset_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Problema ao carregar dataset {dataset_name}: {e}\")\n"
   ],
   "id": "49e16e93b83d2422",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Gerando resultados com o classficador Ridge, transformações e convoluções",
   "id": "def0ecfbb9eff538"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-28T23:05:48.299576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processes_datasets = multivariate\n",
    "\n",
    "for dataset_name in processes_datasets:\n",
    "    try:\n",
    "        if df_results[\n",
    "            (df_results[\"dataset\"] == dataset_name)\n",
    "            & ~(df_results[\"representation\"].isnull())\n",
    "        ].shape[0] == len(reps) * len(operations) * 3: # Teste sem convolução, com Rocket e com MiniRocket\n",
    "            logger.info(f\"Dataset {dataset_name} já processado.\")\n",
    "            continue\n",
    "\n",
    "        dataset = load_dataset(dataset_name, config.DATASETS_FOLDER)\n",
    "        X_train = dataset[\"X_train\"]\n",
    "        y_train = dataset[\"y_train\"]\n",
    "        X_test = dataset[\"X_test\"]\n",
    "        y_test = dataset[\"y_test\"]\n",
    "        \n",
    "        for representation in reps:\n",
    "            if df_results[\n",
    "                (df_results[\"dataset\"] == dataset_name)\n",
    "                & (df_results[\"representation\"] == representation)\n",
    "            ].shape[0] == len(operations) * 3: # Teste sem convolução, com Rocket e com MiniRocket \n",
    "                logger.info(f\"Dataset {dataset_name} com representação {representation} já processado.\")\n",
    "                continue\n",
    "            \n",
    "            logger.info(f\"Iniciando o processo de transformação das dimensões na representação {representation}\")\n",
    "\n",
    "            transformed_train_series = []\n",
    "            for exemple in X_train:\n",
    "                exemple_processed = []\n",
    "                for series in exemple:\n",
    "                    if len(series) > 300:\n",
    "                        series = PAA(series, 300) \n",
    "                    t = transform_series(series, representation)\n",
    "                    exemple_processed.append(t)\n",
    "                transformed_train_series.append(exemple_processed)\n",
    "            transformed_test_series = []\n",
    "            for exemple in X_test:\n",
    "                exemple_processed= []\n",
    "                for series in exemple:\n",
    "                    if len(series) > 300:\n",
    "                        series = PAA(series, 300)\n",
    "                    t = transform_series(series, representation)\n",
    "                    exemple_processed.append(t)\n",
    "                transformed_test_series.append(exemple_processed)\n",
    "\n",
    "            logger.info(\"Finalizado processo de transformação das dimensões com sucesso\")\n",
    "\n",
    "            for operation in operations:\n",
    "                if df_results[\n",
    "                    (df_results[\"dataset\"] == dataset_name)\n",
    "                    & (df_results[\"representation\"] == representation)\n",
    "                    & (df_results[\"operation\"] == operation)\n",
    "                ].shape[0] == 3: # Teste sem convolução, com Rocket e com MiniRocket \n",
    "                    logger.info(f\"Dataset {dataset_name}, representação {representation} e operação {operation} todos as variações já processadas.\")\n",
    "                    continue\n",
    "                \n",
    "                logger.info(f\"Iniciando processo de fusão das dimensões na operação {operation}\")\n",
    "                X_train_transformed = dimensions_fusion(transformed_train_series, operation)\n",
    "                X_test_transformed = dimensions_fusion(transformed_test_series, operation)\n",
    "                \n",
    "                logger.info(\"Finalizado processo de fusão\")\n",
    "\n",
    "                try:\n",
    "                    if df_results[\n",
    "                        (df_results[\"dataset\"] == dataset_name)\n",
    "                        & (df_results[\"representation\"] == representation)\n",
    "                        & (df_results[\"operation\"] == operation)\n",
    "                        & (df_results[\"convolution_algorithm\"].isnull())\n",
    "                    ].shape[0] == 0:\n",
    "                        logger.info(\"Iniciando processo de treinamento apenas com o classificador Ridge\")\n",
    "                        classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "                        classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "                        accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "                        new_result_line = {\n",
    "                            \"dataset\": dataset_name,\n",
    "                            \"representation\": representation,\n",
    "                            \"operation\": operation,\n",
    "                            \"accuracy\": accuracy,\n",
    "                            \"convolution_algorithm\": None,\n",
    "                            \"classification_algorithm\": \"Ridge\",\n",
    "                        }\n",
    "                        df_results.loc[len(df_results)] = new_result_line\n",
    "                        df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "                    else:\n",
    "                        logger.info(f\"Dataset {dataset_name} com representação {representation}, operação {operation} e sem convolução já processado.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Problema com o dataset {dataset_name} com o classificador Ridge: {e}\")\n",
    "\n",
    "                try:\n",
    "                    if df_results[\n",
    "                        (df_results[\"dataset\"] == dataset_name)\n",
    "                        & (df_results[\"representation\"] == representation)\n",
    "                        & (df_results[\"operation\"] == operation)\n",
    "                        & (df_results[\"convolution_algorithm\"] == \"Rocket\")\n",
    "                    ].shape[0] == 0:\n",
    "                        logger.info(\"Iniciando processo de treinamento com o classificador Ridge e convolução Rocket\")\n",
    "\n",
    "                        algorithm = Rocket(n_kernels=10000, n_jobs=-1, random_state=6)\n",
    "                        algorithm.fit(X_train_transformed)\n",
    "\n",
    "                        X_train_transformed = algorithm.transform(X_train_transformed)\n",
    "                        X_test_transformed = algorithm.transform(X_test_transformed)\n",
    "\n",
    "                        classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "                        classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "                        accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "                        new_result_line = {\n",
    "                            \"dataset\": dataset_name,\n",
    "                            \"representation\": representation,\n",
    "                            \"operation\": operation,\n",
    "                            \"accuracy\": accuracy,\n",
    "                            \"convolution_algorithm\": \"Rocket\",\n",
    "                            \"classification_algorithm\": \"Ridge\",\n",
    "                        }\n",
    "                        df_results.loc[len(df_results)] = new_result_line\n",
    "                        df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "                    else:\n",
    "                        logger.info(f\"Dataset {dataset_name} com representação {representation}, operação {operation} e com convolução Rocket já processado.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Problema com o dataset {dataset_name} usando Rocket: {e}\")\n",
    "\n",
    "                try:\n",
    "                    if df_results[\n",
    "                        (df_results[\"dataset\"] == dataset_name)\n",
    "                        & (df_results[\"representation\"] == representation)\n",
    "                        & (df_results[\"operation\"] == operation)\n",
    "                        & (df_results[\"convolution_algorithm\"] == \"MiniRocket\")\n",
    "                    ].shape[0] == 0:\n",
    "                        logger.info(\"Iniciando processo de treinamento com o classificador Ridge e convolução MiniRocket\")\n",
    "\n",
    "                        algorithm = MiniRocket(n_kernels=10000, n_jobs=-1, random_state=6)\n",
    "                        algorithm.fit(X_train_transformed)\n",
    "\n",
    "                        X_train_transformed = algorithm.transform(X_train_transformed)\n",
    "                        X_test_transformed = algorithm.transform(X_test_transformed)\n",
    "\n",
    "                        classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "                        classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "                        accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "                        new_result_line = {\n",
    "                            \"dataset\": dataset_name,\n",
    "                            \"representation\": representation,\n",
    "                            \"operation\": operation,\n",
    "                            \"accuracy\": accuracy,\n",
    "                            \"convolution_algorithm\": \"MiniRocket\",\n",
    "                            \"classification_algorithm\": \"Ridge\",\n",
    "                        }\n",
    "                        df_results.loc[len(df_results)] = new_result_line\n",
    "                        df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n",
    "                    else:\n",
    "                        logger.info(f\"Dataset {dataset_name} com representação {representation}, operação {operation} e com convolução MiniRocket já processado.\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Problema com o dataset {dataset_name} usando MiniRocket: {e}\")\n",
    "\n",
    "        logger.info(f\"Finalizado o processamento do dataset {dataset_name}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Problema ao carregar dataset {dataset_name}: {e}\")\n",
    "    \n",
    "logger.info(\"Finalizado o processamento de todos os datasets.\")\n"
   ],
   "id": "29954c0c17ff2448",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
