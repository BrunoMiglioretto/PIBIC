{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-25T17:20:33.326709Z",
     "start_time": "2025-06-25T17:20:29.994379Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from aeon.transformations.collection.convolution_based import Rocket, MiniRocket\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from utils import config\n",
    "from utils.utils import transform_series, dimensions_fusion, load_dataset, PAA"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T17:20:34.174830Z",
     "start_time": "2025-06-25T17:20:34.171445Z"
    }
   },
   "cell_type": "code",
   "source": "RESULTS_FILENAME = f'results_final.csv'",
   "id": "f9de8396b767760b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T17:20:35.688886Z",
     "start_time": "2025-06-25T17:20:35.678975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    df_results = pd.read_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\")\n",
    "except FileNotFoundError:\n",
    "    df_results = pd.DataFrame(columns=[\n",
    "        \"dataset\",\n",
    "        \"representation\",\n",
    "        \"operation\",\n",
    "        \"accuracy\",\n",
    "        \"convolution_algorithm\",\n",
    "        \"classification_algorithm\",\n",
    "    ])\n"
   ],
   "id": "e4b758a70ab9cf26",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T17:20:38.134386Z",
     "start_time": "2025-06-25T17:20:37.577784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from aeon.datasets import load_from_ts_file, load_classification\n",
    "\n",
    "dataset_name = \"LSST\"\n",
    "representation = \"CWT\"\n",
    "operation = \"sum\"\n",
    "\n",
    "dataset = load_dataset(dataset_name, config.DATASETS_FOLDER)\n",
    "\n",
    "X_train, y_train = load_from_ts_file(f\"{config.DATASETS_FOLDER}/{dataset_name}/{dataset_name}_TRAIN.ts\")\n",
    "X_test, y_test = load_from_ts_file(f\"{config.DATASETS_FOLDER}/{dataset_name}/{dataset_name}_TEST.ts\")\n",
    "\n",
    "# X_train, y_train = load_classification(dataset_name, split=\"Train\")\n",
    "# X_test, y_test = load_classification(dataset_name, split=\"Test\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = dataset[\"X_train\"]\n",
    "y_train = dataset[\"y_train\"]\n",
    "X_test = dataset[\"X_test\"]\n",
    "y_test = dataset[\"y_test\"]\n",
    "\n"
   ],
   "id": "4e93464dc4d89ea2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T17:21:59.130878Z",
     "start_time": "2025-06-25T17:21:59.127738Z"
    }
   },
   "cell_type": "code",
   "source": "series = X_train[0][0]",
   "id": "5efd71105f64366b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T17:22:44.062818Z",
     "start_time": "2025-06-25T17:22:44.057872Z"
    }
   },
   "cell_type": "code",
   "source": "series",
   "id": "e9b43e774cc64d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  17.597  ,    0.22974,  -29.654  ,  -59.21   ,  -72.064  ,\n",
       "        -58.355  ,  -24.086  ,    9.5313 ,   19.02   ,   -3.35   ,\n",
       "        -40.648  ,  -61.347  ,  -43.567  ,    4.9636 ,   49.192  ,\n",
       "         52.197  ,    4.6215 ,  -66.308  , -116.57   , -118.12   ,\n",
       "        -77.84   ,  -28.137  ,    0.75407,    2.2877 ,   -7.7249 ,\n",
       "        -10.118  ,    0.80155,   17.232  ,   31.031  ,   43.985  ,\n",
       "         64.09   ,   92.687  ,  117.42   ,  119.82   ,   91.591  ,\n",
       "         43.719  ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T17:23:29.181781Z",
     "start_time": "2025-06-25T17:23:25.723424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# \n",
    "series = X_train[0][0]\n",
    "\n",
    "series_transformed = transform_series(series, \"CWT\")\n",
    "\n",
    "fusioned_series = dusion_\n"
   ],
   "id": "cf5726acfc05057e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-25T17:23:30.207706Z",
     "start_time": "2025-06-25T17:23:30.202687Z"
    }
   },
   "cell_type": "code",
   "source": "something.flatten()",
   "id": "7e93b5542b4b07a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.54545455,  1.12680094, -0.1171813 , ...,  1.02373224,\n",
       "        0.56935552,  1.54545455])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ecd034ed58d244f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:47:16.187052Z",
     "start_time": "2025-06-15T23:47:12.415104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "series_length = min([min([len(dimension) for dimension in case]) for case in X_train])\n",
    "a = []\n",
    "for case in X_train:\n",
    "    s = []\n",
    "    for series in case:\n",
    "        p = PAA(series, series_length)\n",
    "        s.append(p)\n",
    "    a.append(np.array(s))\n",
    "X_train = a\n",
    "\n",
    "# print(X_train.shape)\n",
    "\n",
    "#series_length = int(mean([mean([len(dimension) for dimension in case]) for case in X_test]))\n",
    "series_length = min([min([len(dimension) for dimension in case]) for case in X_test])\n",
    "b = []\n",
    "for case in X_test:\n",
    "    s = []\n",
    "    for series in case:\n",
    "        ar = []\n",
    "        p = PAA(series, series_length)\n",
    "        s.append(p)\n",
    "    b.append(s)\n",
    "X_test = b\n"
   ],
   "id": "8103bcafd46d123f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-20T11:13:08.179458Z",
     "start_time": "2025-06-20T11:13:08.135285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "print(np.array(X_train).shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\n",
    "    len(PAA(np.array(X_train)[0][0], 10))\n",
    ")\n"
   ],
   "id": "e9bee51e1abf6f0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 6, 17984)\n",
      "(128,)\n",
      "10\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T23:55:11.137782Z",
     "start_time": "2025-06-23T23:55:11.131273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "something = transform_series(X_train[0][0], \"RP\")\n",
    "PAA(something.flatten(), 300)"
   ],
   "id": "325ea8c66dcb95fa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5 , 0.25, 0.5 , 0.4 , 0.  , 0.5 , 0.6 , 0.  , 0.5 , 0.  , 0.75,\n",
       "       0.25, 0.2 , 0.5 , 1.  , 0.  , 0.  , 0.25, 0.2 , 0.5 , 0.  , 0.2 ,\n",
       "       0.5 , 0.  , 0.  , 0.25, 0.5 , 0.5 , 0.2 , 0.5 , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.6 , 0.  , 0.25, 0.2 , 0.25, 0.  , 0.  , 0.  , 0.5 , 0.2 ,\n",
       "       0.75, 0.25, 0.2 , 0.  , 0.  , 0.  , 0.25, 0.25, 0.5 , 0.2 , 0.  ,\n",
       "       0.5 , 0.2 , 0.  , 0.5 , 0.  , 0.75, 0.25, 0.2 , 0.5 , 1.  , 0.2 ,\n",
       "       0.25, 0.25, 0.6 , 0.25, 0.25, 0.2 , 0.5 , 0.5 , 0.  , 0.5 , 0.5 ,\n",
       "       0.5 , 0.4 , 0.  , 0.75, 0.6 , 0.  , 0.  , 0.8 , 0.25, 0.5 , 0.  ,\n",
       "       0.25, 0.  , 0.  , 0.  , 0.5 , 0.2 , 0.75, 0.25, 0.2 , 0.  , 0.  ,\n",
       "       0.  , 0.5 , 0.5 , 0.5 , 0.2 , 0.25, 0.25, 0.  , 0.  , 0.5 , 0.  ,\n",
       "       0.75, 0.25, 0.2 , 0.5 , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.5 ,\n",
       "       0.  , 0.  , 0.75, 0.2 , 0.  , 0.  , 0.  , 0.4 , 0.  , 0.  , 0.4 ,\n",
       "       0.25, 0.75, 0.  , 0.75, 0.25, 0.2 , 0.5 , 1.  , 0.  , 0.  , 0.5 ,\n",
       "       0.2 , 0.5 , 0.25, 0.2 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.5 , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.4 , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.5 , 0.2 , 0.25, 0.25, 0.2 , 0.  , 0.  , 0.  , 0.25,\n",
       "       0.25, 0.25, 0.2 , 0.  , 0.5 , 0.2 , 0.  , 0.5 , 0.  , 0.75, 0.25,\n",
       "       0.2 , 0.5 , 1.  , 0.  , 0.25, 0.25, 0.6 , 0.25, 0.25, 0.2 , 1.  ,\n",
       "       0.25, 0.  , 0.5 , 0.5 , 0.25, 0.4 , 0.  , 1.  , 0.4 , 0.  , 0.25,\n",
       "       0.4 , 0.5 , 0.25, 0.2 , 0.75, 0.75, 0.  , 0.25, 0.25, 0.6 , 0.25,\n",
       "       0.25, 0.2 , 1.  , 0.25, 0.  , 0.5 , 0.25, 0.5 , 0.4 , 0.  , 0.5 ,\n",
       "       0.6 , 0.  , 0.25, 0.  , 0.5 , 0.25, 0.2 , 0.  , 0.25, 0.4 , 0.25,\n",
       "       0.  , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.75, 0.2 , 0.  , 0.  , 0.  ,\n",
       "       0.4 , 0.  , 0.  , 0.2 , 0.25, 0.25, 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.2 , 0.25, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.4 ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.2 , 0.25, 0.  , 0.  , 0.  , 0.5 , 0.  ,\n",
       "       0.  , 0.75, 0.2 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T23:34:38.109477Z",
     "start_time": "2025-06-23T23:34:37.908451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transformed_train_series = []\n",
    "for exemple in X_train[:2]:\n",
    "    exemple_processed = []\n",
    "    for series in exemple:\n",
    "        try:\n",
    "            t = transform_series(series, \"CWT\")\n",
    "            exemple_processed.append(t.flatten())\n",
    "        except:\n",
    "            print(series)\n",
    "    transformed_train_series.append(exemple_processed)\n",
    "transformed_test_series = []\n",
    "# for exemple in X_test:\n",
    "#     exemple_processed= []\n",
    "#     for series in exemple:\n",
    "#         try:\n",
    "#             t = transform_series(series, \"CWT\")\n",
    "#             exemple_processed.append(t.flatten())\n",
    "#         except:\n",
    "#             print(series)\n",
    "#     transformed_test_series.append(exemple_processed)\n"
   ],
   "id": "e3504a57dfbf13d2",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T23:34:41.195764Z",
     "start_time": "2025-06-23T23:34:41.191598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(np.array(transformed_train_series).shape)\n",
    "print(y_train.shape)\n"
   ],
   "id": "fed3133cde7bd690",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 200, 400)\n",
      "(25000,)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T23:34:55.334538Z",
     "start_time": "2025-06-23T23:34:55.331386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_transformed = dimensions_fusion(transformed_train_series, operation)\n",
    "X_test_transformed = dimensions_fusion(transformed_test_series, operation)\n"
   ],
   "id": "76c189a2266b64f4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-23T23:34:58.905279Z",
     "start_time": "2025-06-23T23:34:58.901445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train_transformed.shape)\n",
    "print(len(y_train))"
   ],
   "id": "39dad573844ca427",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 400)\n",
      "25000\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:47:41.564707Z",
     "start_time": "2025-06-15T23:47:39.939202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "new_result_line = {\n",
    "    \"dataset\": dataset_name,\n",
    "    \"representation\": representation,\n",
    "    \"operation\": operation,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"convolution_algorithm\": None,\n",
    "    \"classification_algorithm\": \"Ridge\",\n",
    "}\n",
    "df_results.loc[len(df_results)] = new_result_line\n",
    "df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n"
   ],
   "id": "ff8cd127b553647f",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRidgeClassifierCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      1\u001B[39m classifier = RidgeClassifierCV(alphas=np.logspace(-\u001B[32m3\u001B[39m, \u001B[32m3\u001B[39m, \u001B[32m10\u001B[39m))\n\u001B[32m      2\u001B[39m classifier.fit(X_train_transformed, y_train)\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m accuracy = \u001B[43mclassifier\u001B[49m\u001B[43m.\u001B[49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test_transformed\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      6\u001B[39m new_result_line = {\n\u001B[32m      7\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdataset\u001B[39m\u001B[33m\"\u001B[39m: dataset_name,\n\u001B[32m      8\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mrepresentation\u001B[39m\u001B[33m\"\u001B[39m: representation,\n\u001B[32m   (...)\u001B[39m\u001B[32m     12\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mclassification_algorithm\u001B[39m\u001B[33m\"\u001B[39m: \u001B[33m\"\u001B[39m\u001B[33mRidge\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     13\u001B[39m }\n\u001B[32m     14\u001B[39m df_results.loc[\u001B[38;5;28mlen\u001B[39m(df_results)] = new_result_line\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\sklearn\\base.py:764\u001B[39m, in \u001B[36mClassifierMixin.score\u001B[39m\u001B[34m(self, X, y, sample_weight)\u001B[39m\n\u001B[32m    739\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    740\u001B[39m \u001B[33;03mReturn the mean accuracy on the given test data and labels.\u001B[39;00m\n\u001B[32m    741\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    760\u001B[39m \u001B[33;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001B[39;00m\n\u001B[32m    761\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    762\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m accuracy_score\n\u001B[32m--> \u001B[39m\u001B[32m764\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m accuracy_score(y, \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m, sample_weight=sample_weight)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:1333\u001B[39m, in \u001B[36m_RidgeClassifierMixin.predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m   1331\u001B[39m     scores = \u001B[32m2\u001B[39m * (\u001B[38;5;28mself\u001B[39m.decision_function(X) > \u001B[32m0\u001B[39m) - \u001B[32m1\u001B[39m\n\u001B[32m   1332\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._label_binarizer.inverse_transform(scores)\n\u001B[32m-> \u001B[39m\u001B[32m1333\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:382\u001B[39m, in \u001B[36mLinearClassifierMixin.predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    368\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    369\u001B[39m \u001B[33;03mPredict class labels for samples in X.\u001B[39;00m\n\u001B[32m    370\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    379\u001B[39m \u001B[33;03m    Vector containing the class labels for each sample.\u001B[39;00m\n\u001B[32m    380\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    381\u001B[39m xp, _ = get_namespace(X)\n\u001B[32m--> \u001B[39m\u001B[32m382\u001B[39m scores = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    383\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(scores.shape) == \u001B[32m1\u001B[39m:\n\u001B[32m    384\u001B[39m     indices = xp.astype(scores > \u001B[32m0\u001B[39m, indexing_dtype(xp))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:363\u001B[39m, in \u001B[36mLinearClassifierMixin.decision_function\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    360\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m    361\u001B[39m xp, _ = get_namespace(X)\n\u001B[32m--> \u001B[39m\u001B[32m363\u001B[39m X = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcsr\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    364\u001B[39m scores = safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m.coef_.T, dense_output=\u001B[38;5;28;01mTrue\u001B[39;00m) + \u001B[38;5;28mself\u001B[39m.intercept_\n\u001B[32m    365\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m xp.reshape(scores, (-\u001B[32m1\u001B[39m,)) \u001B[38;5;28;01mif\u001B[39;00m scores.shape[\u001B[32m1\u001B[39m] == \u001B[32m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m scores\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\sklearn\\base.py:633\u001B[39m, in \u001B[36mBaseEstimator._validate_data\u001B[39m\u001B[34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[39m\n\u001B[32m    631\u001B[39m         out = X, y\n\u001B[32m    632\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[32m--> \u001B[39m\u001B[32m633\u001B[39m     out = \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mX\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    634\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[32m    635\u001B[39m     out = _check_y(y, **check_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1064\u001B[39m, in \u001B[36mcheck_array\u001B[39m\u001B[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[39m\n\u001B[32m   1058\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1059\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[33m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m expected <= 2.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1060\u001B[39m         % (array.ndim, estimator_name)\n\u001B[32m   1061\u001B[39m     )\n\u001B[32m   1063\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[32m-> \u001B[39m\u001B[32m1064\u001B[39m     \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1065\u001B[39m \u001B[43m        \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1066\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1067\u001B[39m \u001B[43m        \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1068\u001B[39m \u001B[43m        \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mallow-nan\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   1069\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1071\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[32m   1072\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[32m   1073\u001B[39m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001B[39m, in \u001B[36m_assert_all_finite\u001B[39m\u001B[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    120\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[32m    121\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m123\u001B[39m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[43m=\u001B[49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    126\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m=\u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    129\u001B[39m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    130\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\puc\\iniciacao\\projeto\\venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001B[39m, in \u001B[36m_assert_all_finite_element_wise\u001B[39m\u001B[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[39m\n\u001B[32m    155\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name == \u001B[33m\"\u001B[39m\u001B[33mX\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[32m    156\u001B[39m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[32m    157\u001B[39m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[32m    158\u001B[39m     msg_err += (\n\u001B[32m    159\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m does not accept missing values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    160\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    170\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m#estimators-that-handle-nan-values\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    171\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[31mValueError\u001B[39m: Input X contains NaN.\nRidgeClassifierCV does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "algorithm = Rocket(n_kernels=10000, n_jobs=-1, random_state=6)\n",
    "algorithm.fit(X_train_transformed)\n",
    "\n",
    "X_train_transformed = algorithm.transform(X_train_transformed)\n",
    "X_test_transformed = algorithm.transform(X_test_transformed)\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "new_result_line = {\n",
    "    \"dataset\": dataset_name,\n",
    "    \"representation\": representation,\n",
    "    \"operation\": operation,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"convolution_algorithm\": \"Rocket\",\n",
    "    \"classification_algorithm\": \"Ridge\",\n",
    "}\n",
    "df_results.loc[len(df_results)] = new_result_line\n",
    "df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n"
   ],
   "id": "3f42c1b4465076a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "algorithm = MiniRocket(n_kernels=10000, n_jobs=-1, random_state=6)\n",
    "algorithm.fit(X_train_transformed)\n",
    "\n",
    "X_train_transformed = algorithm.transform(X_train_transformed)\n",
    "X_test_transformed = algorithm.transform(X_test_transformed)\n",
    "\n",
    "classifier = RidgeClassifierCV(alphas=np.logspace(-3, 3, 10))\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "accuracy = classifier.score(X_test_transformed, y_test)\n",
    "\n",
    "new_result_line = {\n",
    "    \"dataset\": dataset_name,\n",
    "    \"representation\": representation,\n",
    "    \"operation\": operation,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"convolution_algorithm\": \"MiniRocket\",\n",
    "    \"classification_algorithm\": \"Ridge\",\n",
    "}\n",
    "df_results.loc[len(df_results)] = new_result_line\n",
    "df_results.to_csv(f\"{config.RESULTS_FOLDER}/{RESULTS_FILENAME}\", index=False)\n"
   ],
   "id": "3fcc25b2293e8b87",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
